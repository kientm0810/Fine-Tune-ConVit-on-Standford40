# ðŸŽ¬ Human Action Recognition with ConViT + YOLOv8 (Demo)

This is a Streamlit-based demo for recognizing human actions from still images using a fine-tuned **ConViT model** on the Stanford40 dataset. **YOLOv8** is used only for detecting the person and cropping the input region to reduce background clutter.

---

## ðŸš€ How to Run the Demo

### 1. Install dependencies

```bash
pip install -r requirements.txt
```

### 2. Download model weights:
Place your fine-tuned ConViT weights file at: /DEMO/

### 3. Launch the Streamlit app
``` bash
streamlit run DEMO/app.py
```
The app will capture a frame from your webcam every 5 seconds.

YOLOv8 detects the person and crops the region.

ConViT predicts the action label and displays it with a bounding box.

ðŸ“‚ Project Structure
```pgsql
â”œâ”€â”€ Phase1_89mAP/              # Phase 1: ConViT with frozen backbone
â”œâ”€â”€ Phase2_93.25mAP/           # Phase 2: ConViT with last 2 blocks unfrozen
â”œâ”€â”€ DEMO/
â”‚   â”œâ”€â”€ app.py                 # Streamlit demo: YOLOv8 + ConViT pipeline
â”‚   â”œâ”€â”€ best_yoloS.pt.py               # Utility functions for preprocessing
â”‚   â””â”€â”€ best_convit_stanford40.pth.pth   # Your trained ConViT model checkpoint
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
